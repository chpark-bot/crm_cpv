import streamlit as st
import pandas as pd
from datetime import timedelta
import numpy as np
import re

# --- 1. ëŒ€ì‹œë³´ë“œ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(layout="wide", page_title="ì´ë²¤íŠ¸ ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.title("ë°”ë¹„í†¡ ì´ë²¤íŠ¸ ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("---")

# ì¦ê°ìœ¨ ê³„ì‚° í•¨ìˆ˜ (ë¬¸ìì—´ í¬ë§·: +10.00%)
def calculate_rate_str(current, previous, change):
    if previous == 0 and current > 0:
        return "+100.00%" 
    elif previous == 0 and current == 0:
        return "0.00%"
    else:
        rate = (change / previous) * 100
        return f"{rate:+.2f}%" 

# ì¦ê°ìœ¨ ê³„ì‚° í•¨ìˆ˜ (ìˆœìˆ˜ ìˆ«ì ê°’: 10.00)
def calculate_rate_num(current, previous, change):
    if previous == 0 and current > 0:
        return 100.0
    elif previous == 0 and current == 0:
        return 0.0
    else:
        return (change / previous) * 100

# --- 2. ë°ì´í„° ì—…ë¡œë“œ ---
uploaded_file = st.file_uploader("ë¶„ì„í•  CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type=["csv"])

if uploaded_file is not None:
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"CSV íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ì¸ì½”ë”©(UTF-8 ì¶”ì²œ) ë˜ëŠ” í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")
        st.stop()


    # --- 3. ë°ì´í„° ì „ì²˜ë¦¬ (ì˜¤ë¥˜ ë°©ì§€ ë° ì»¬ëŸ¼ëª… ì •ë¦¬ ê°•í™”) ---
    
    # 3-1. ì»¬ëŸ¼ëª… ì •ë¦¬ ë° í™•ì¸
    df.columns = df.columns.str.strip() # ì»¬ëŸ¼ëª… ì•ë’¤ ê³µë°± ì œê±°
    
    required_cols = ['ë³‘ì›ëª…', 'ì´ë²¤íŠ¸ ID', 'ì´ë²¤íŠ¸ëª…', 'ëŒ€ìƒì¼', 'CPV ì¡°íšŒ ìˆ˜', 'CPV ë§¤ì¶œ']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        st.error(f"CSV íŒŒì¼ì— ë‹¤ìŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
        st.info("âš ï¸ CSV íŒŒì¼ì„ ì—´ì–´ ì»¬ëŸ¼ëª…(ëŒ€ì†Œë¬¸ì, ë„ì–´ì“°ê¸° í¬í•¨)ì´ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # 3-2. ìˆ«ì ì²˜ë¦¬ (CPV ì¡°íšŒ ìˆ˜, CPV ë§¤ì¶œ)
    for col in ['CPV ì¡°íšŒ ìˆ˜', 'CPV ë§¤ì¶œ']:
        try:
            # ì‰¼í‘œ, í•œê¸€('ì›' ë“±), íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜
            df[col] = df[col].astype(str).str.replace(r'[^\d.]', '', regex=True)
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        except Exception:
            df[col] = 0
            
    # 3-3. ë‚ ì§œ ì²˜ë¦¬ (ëŒ€ìƒì¼)
    try:
        df['ëŒ€ìƒì¼'] = pd.to_datetime(df['ëŒ€ìƒì¼'], errors='coerce')
        df.dropna(subset=['ëŒ€ìƒì¼'], inplace=True)
        
        if df.empty:
            st.warning("ìœ íš¨í•œ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        min_date_data = df['ëŒ€ìƒì¼'].min().date()
        max_date_data = df['ëŒ€ìƒì¼'].max().date()
        
    except Exception as e:
        st.error(f"ë‚ ì§œ ì»¬ëŸ¼('ëŒ€ìƒì¼') ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‚ ì§œ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")
        st.stop()
    
    
    # --- 4. ê¸°íšì „ ê¸°ê°„ ì„¤ì • í•„í„° (ì‚¬ì´ë“œë°”) ---
    st.sidebar.header("ğŸ—“ï¸ ê¸°ê°„ ì„¤ì • (Promotion Period)")

    start_date_input, end_date_input = st.sidebar.date_input(
        "ê¸°íšì „ ì§„í–‰ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”:",
        [min_date_data, max_date_data],
        min_value=min_date_data,
        max_value=max_date_data
    )

    start_date = pd.to_datetime(start_date_input)
    end_date = pd.to_datetime(end_date_input)
    
    if start_date > end_date:
        st.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ë¹¨ë¼ì•¼ í•©ë‹ˆë‹¤. ë‚ ì§œë¥¼ ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        st.stop()
        
    # --- 5. ì´ì „ ë™ê¸°ê°„ ê³„ì‚° ---
    
    period_duration = end_date - start_date
    prev_end_date = start_date - timedelta(days=1)
    prev_start_date = prev_end_date - period_duration
    
    st.sidebar.markdown(f"**ì„ íƒ ê¸°ê°„:** {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
    st.sidebar.markdown(f"**ì´ì „ ë™ê¸°ê°„:** {prev_start_date.strftime('%Y-%m-%d')} ~ {prev_end_date.strftime('%Y-%m-%d')}")


    # --- 6. ê¸°ê°„ë³„ ë°ì´í„° í•„í„°ë§ ---
    
    current_df = df[
        (df['ëŒ€ìƒì¼'] >= start_date) & 
        (df['ëŒ€ìƒì¼'] <= end_date)
    ].copy()
    
    prev_df = df[
        (df['ëŒ€ìƒì¼'] >= prev_start_date) & 
        (df['ëŒ€ìƒì¼'] <= prev_end_date)
    ].copy()

    if current_df.empty:
        st.warning("ì„ íƒí•˜ì‹  ê¸°íšì „ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # --- 7. í†µí•© ë¶„ì„ ë°ì´í„°í”„ë ˆì„ ìƒì„± ---
    
    group_keys = ['ì´ë²¤íŠ¸ëª…', 'ë³‘ì›ëª…', 'ì´ë²¤íŠ¸ ID']

    current_event_summary = current_df.groupby(group_keys).agg(
        {'CPV ì¡°íšŒ ìˆ˜': 'sum', 'CPV ë§¤ì¶œ': 'sum'}
    ).reset_index().rename(columns={'CPV ì¡°íšŒ ìˆ˜': 'í˜„ì¬ ì¡°íšŒ ìˆ˜', 'CPV ë§¤ì¶œ': 'í˜„ì¬ ë§¤ì¶œ'})

    prev_event_summary = prev_df.groupby(group_keys).agg(
        {'CPV ì¡°íšŒ ìˆ˜': 'sum', 'CPV ë§¤ì¶œ': 'sum'}
    ).reset_index().rename(columns={'CPV ì¡°íšŒ ìˆ˜': 'ì´ì „ ì¡°íšŒ ìˆ˜', 'CPV ë§¤ì¶œ': 'ì´ì „ ë§¤ì¶œ'})

    event_analysis = pd.merge(
        current_event_summary, 
        prev_event_summary[['ì´ë²¤íŠ¸ëª…', 'ë³‘ì›ëª…', 'ì´ë²¤íŠ¸ ID', 'ì´ì „ ì¡°íšŒ ìˆ˜', 'ì´ì „ ë§¤ì¶œ']], 
        on=group_keys, 
        how='left'
    ).fillna(0)

    event_analysis['ì¡°íšŒìˆ˜ ì¦ê°ì•¡'] = event_analysis['í˜„ì¬ ì¡°íšŒ ìˆ˜'] - event_analysis['ì´ì „ ì¡°íšŒ ìˆ˜']
    event_analysis['ë§¤ì¶œ ì¦ê°ì•¡'] = event_analysis['í˜„ì¬ ë§¤ì¶œ'] - event_analysis['ì´ì „ ë§¤ì¶œ']

    event_analysis['ì¡°íšŒìˆ˜ ì¦ê°ë¥  (%)'] = event_analysis.apply(
        lambda row: calculate_rate_num(row['í˜„ì¬ ì¡°íšŒ ìˆ˜'], row['ì´ì „ ì¡°íšŒ ìˆ˜'], row['ì¡°íšŒìˆ˜ ì¦ê°ì•¡']), 
        axis=1
    )
    event_analysis['ë§¤ì¶œ ì¦ê°ë¥  (%)'] = event_analysis.apply(
        lambda row: calculate_rate_num(row['í˜„ì¬ ë§¤ì¶œ'], row['ì´ì „ ë§¤ì¶œ'], row['ë§¤ì¶œ ì¦ê°ì•¡']), 
        axis=1
    )
    
    # --- 8. í•µì‹¬ ì§€í‘œ ì‹œê°í™” (ìƒë‹¨ ì´í•©) ---
    
    current_views = event_analysis['í˜„ì¬ ì¡°íšŒ ìˆ˜'].sum()
    current_revenue = event_analysis['í˜„ì¬ ë§¤ì¶œ'].sum()
    
    prev_views = event_analysis['ì´ì „ ì¡°íšŒ ìˆ˜'].sum()
    prev_revenue = event_analysis['ì´ì „ ë§¤ì¶œ'].sum()
    
    views_change = current_views - prev_views
    revenue_change = current_revenue - prev_revenue

    views_rate_str = calculate_rate_str(current_views, prev_views, views_change)
    revenue_rate_str = calculate_rate_str(current_revenue, prev_revenue, revenue_change)
    
    st.header("ğŸ“ˆ ê¸°íšì „ ì„±ê³¼ ì¦ê° ë¶„ì„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric(
            label="ì´ CPV ì¡°íšŒ ìˆ˜", 
            value=f"{int(current_views):,}", 
            delta=f"{int(views_change):,} ({views_rate_str})"
        )
    
    with col2:
        st.metric(
            label="ì´ CPV ë§¤ì¶œ", 
            value=f"{int(current_revenue):,} ì›", 
            delta=f"{int(revenue_change):,} ì› ({revenue_rate_str})"
        )

    st.markdown("---")

    # --- 9. TOP 3 ë­í‚¹ ---
    
    st.header("ğŸ† ì´ë²¤íŠ¸ TOP 3 ë­í‚¹ (ì„ íƒ ê¸°ê°„)")
    
    # ë­í‚¹ í…Œì´ë¸” ì¶œë ¥ì„ ìœ„í•œ í¬ë§·ëœ ì»¬ëŸ¼ ìƒì„±
    event_analysis['CPV ì¡°íšŒ ìˆ˜ (ë­í‚¹ìš©)'] = event_analysis.apply(
        lambda row: f"{int(row['í˜„ì¬ ì¡°íšŒ ìˆ˜']):,} ({calculate_rate_str(row['í˜„ì¬ ì¡°íšŒ ìˆ˜'], row['ì´ì „ ì¡°íšŒ ìˆ˜'], row['ì¡°íšŒìˆ˜ ì¦ê°ì•¡'])})", 
        axis=1
    )
    event_analysis['CPV ë§¤ì¶œ (ë­í‚¹ìš©)'] = event_analysis.apply(
        lambda row: f"{int(row['í˜„ì¬ ë§¤ì¶œ']):,} ì› ({calculate_rate_str(row['í˜„ì¬ ë§¤ì¶œ'], row['ì´ì „ ë§¤ì¶œ'], row['ë§¤ì¶œ ì¦ê°ì•¡'])})", 
        axis=1
    )

    ranking_cols_views = ['ì´ë²¤íŠ¸ëª…', 'ë³‘ì›ëª…', 'CPV ì¡°íšŒ ìˆ˜ (ë­í‚¹ìš©)']
    ranking_cols_revenue = ['ì´ë²¤íŠ¸ëª…', 'ë³‘ì›ëª…', 'CPV ë§¤ì¶œ (ë­í‚¹ìš©)']
    
    col3, col4 = st.columns(2)
    
    with col3:
        st.subheader("ì¡°íšŒ ìˆ˜ TOP 3 ì´ë²¤íŠ¸")
        top3_views = event_analysis.sort_values(by='í˜„ì¬ ì¡°íšŒ ìˆ˜', ascending=False).head(3)[ranking_cols_views]
        st.dataframe(top3_views, use_container_width=True, hide_index=True)
        
    with col4:
        st.subheader("CPV ë§¤ì¶œ TOP 3 ì´ë²¤íŠ¸")
        top3_revenue = event_analysis.sort_values(by='í˜„ì¬ ë§¤ì¶œ', ascending=False).head(3)[ranking_cols_revenue]
        st.dataframe(top3_revenue, use_container_width=True, hide_index=True)

    st.markdown("---")


    # --- 10. ì´ë²¤íŠ¸ë³„ ìƒì„¸ ì„±ê³¼ í…Œì´ë¸” (NEW) ---
    st.header("ğŸ“‹ ì´ë²¤íŠ¸ë³„ ìƒì„¸ ì„±ê³¼")
    
    # ìµœì¢… í…Œì´ë¸” ì»¬ëŸ¼ ë§¤í•‘ ë° ì •ë¦¬ (CPVë§¤ì¶œ ì»¬ëŸ¼ ì¶”ê°€ ë°˜ì˜)
    detailed_cols_map = {
        'ì´ë²¤íŠ¸ëª…': 'ì´ë²¤íŠ¸ëª…',
        'ë³‘ì›ëª…': 'ë³‘ì›ëª…',
        'ì´ë²¤íŠ¸ ID': 'ì´ë²¤íŠ¸ ID',
        'í˜„ì¬ ì¡°íšŒ ìˆ˜': 'ì¡°íšŒìˆ˜',
        'ì¡°íšŒìˆ˜ ì¦ê°ì•¡': 'ì¡°íšŒìˆ˜ ì¦ê°ëŸ‰',
        'ì¡°íšŒìˆ˜ ì¦ê°ë¥  (%)': 'ì¡°íšŒìˆ˜ ì¦ê°ë¥ (%)',
        'í˜„ì¬ ë§¤ì¶œ': 'CPVë§¤ì¶œ',             # <-- ì¶”ê°€ëœ ì»¬ëŸ¼
        'ë§¤ì¶œ ì¦ê°ì•¡': 'CPVë§¤ì¶œ ì¦ê°ì•¡',
        'ë§¤ì¶œ ì¦ê°ë¥  (%)': 'CPVë§¤ì¶œ ì¦ê°ë¥ (%)'
    }

    final_detailed_df = event_analysis[detailed_cols_map.keys()].rename(columns=detailed_cols_map)
    
    # DataFrame í¬ë§·íŒ…: CPVë§¤ì¶œ ì»¬ëŸ¼ í¬ë§· ì¶”ê°€ ë°˜ì˜
    st.dataframe(
        final_detailed_df.style.format({
            'ì¡°íšŒìˆ˜': "{:,.0f}", 
            'ì¡°íšŒìˆ˜ ì¦ê°ëŸ‰': "{:+.0f}",
            'ì¡°íšŒìˆ˜ ì¦ê°ë¥ (%)': "{:+.2f}%",
            'CPVë§¤ì¶œ': "{:,.0f} ì›",          # <-- ì¶”ê°€ëœ ì»¬ëŸ¼ í¬ë§·
            'CPVë§¤ì¶œ ì¦ê°ì•¡': "{:+.0f} ì›",
            'CPVë§¤ì¶œ ì¦ê°ë¥ (%)': "{:+.2f}%"
        }),
        use_container_width=True,
        hide_index=True
    )


# ë°ì´í„°ê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ì•ˆë‚´ ë©”ì‹œì§€
else:
    st.info("â¬†ï¸ ì¢Œì¸¡ ìƒë‹¨ì˜ 'Browse files' ë²„íŠ¼ì„ ëˆŒëŸ¬ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ëŒ€ì‹œë³´ë“œë¥¼ ì‹œì‘í•˜ì„¸ìš”.")